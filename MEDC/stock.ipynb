{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e159cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, mean_squared_error, mean_absolute_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7cb8070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(SEED=42):\n",
    "    torch.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c3936a",
   "metadata": {},
   "source": [
    "# Preprocess Stock Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "719662cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_df = pd.read_csv('Page.csv')\n",
    "tickers = page_df['ticker'].unique().tolist()\n",
    "tickers = [ticker + '.JK' for ticker in tickers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89983c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064159/224071114.py:16: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  raw\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2005-04-01</td>\n",
       "      <td>408.560736</td>\n",
       "      <td>429.405656</td>\n",
       "      <td>408.560736</td>\n",
       "      <td>421.067688</td>\n",
       "      <td>6336749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2005-04-08</td>\n",
       "      <td>429.405713</td>\n",
       "      <td>579.489169</td>\n",
       "      <td>429.405713</td>\n",
       "      <td>529.461365</td>\n",
       "      <td>206700352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2005-04-15</td>\n",
       "      <td>521.123391</td>\n",
       "      <td>550.306183</td>\n",
       "      <td>512.785332</td>\n",
       "      <td>521.123352</td>\n",
       "      <td>27473244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2005-04-22</td>\n",
       "      <td>516.954428</td>\n",
       "      <td>516.954428</td>\n",
       "      <td>462.757603</td>\n",
       "      <td>475.264557</td>\n",
       "      <td>42606369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2005-04-29</td>\n",
       "      <td>475.264542</td>\n",
       "      <td>475.264542</td>\n",
       "      <td>429.405670</td>\n",
       "      <td>429.405670</td>\n",
       "      <td>32741619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2025-02-28</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>157145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2025-03-07</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>1035.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>155914900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2025-03-14</td>\n",
       "      <td>1010.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>985.000000</td>\n",
       "      <td>995.000000</td>\n",
       "      <td>148779500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2025-03-21</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>975.000000</td>\n",
       "      <td>175640800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2025-03-28</td>\n",
       "      <td>985.000000</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>945.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>99974600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1037 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price   Ticker       Date         Open         High          Low        Close  \\\n",
       "0      MEDC.JK 2005-04-01   408.560736   429.405656   408.560736   421.067688   \n",
       "1      MEDC.JK 2005-04-08   429.405713   579.489169   429.405713   529.461365   \n",
       "2      MEDC.JK 2005-04-15   521.123391   550.306183   512.785332   521.123352   \n",
       "3      MEDC.JK 2005-04-22   516.954428   516.954428   462.757603   475.264557   \n",
       "4      MEDC.JK 2005-04-29   475.264542   475.264542   429.405670   429.405670   \n",
       "...        ...        ...          ...          ...          ...          ...   \n",
       "1032   MEDC.JK 2025-02-28  1060.000000  1060.000000  1000.000000  1000.000000   \n",
       "1033   MEDC.JK 2025-03-07  1020.000000  1035.000000   990.000000  1005.000000   \n",
       "1034   MEDC.JK 2025-03-14  1010.000000  1025.000000   985.000000   995.000000   \n",
       "1035   MEDC.JK 2025-03-21  1000.000000  1025.000000   900.000000   975.000000   \n",
       "1036   MEDC.JK 2025-03-28   985.000000  1040.000000   945.000000  1025.000000   \n",
       "\n",
       "Price     Volume  \n",
       "0        6336749  \n",
       "1      206700352  \n",
       "2       27473244  \n",
       "3       42606369  \n",
       "4       32741619  \n",
       "...          ...  \n",
       "1032   157145100  \n",
       "1033   155914900  \n",
       "1034   148779500  \n",
       "1035   175640800  \n",
       "1036    99974600  \n",
       "\n",
       "[1037 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = '2005-04-01'\n",
    "end_date   = '2025-03-31'\n",
    "interval   = '1d'\n",
    "tickers = ['MEDC.JK']\n",
    "\n",
    "raw = yf.download(\n",
    "    tickers=tickers,\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    interval=interval,\n",
    "    group_by='ticker',\n",
    "    progress=False\n",
    ")\n",
    "\n",
    "df = (\n",
    "    raw\n",
    "    .stack(level=0)\n",
    "    .rename_axis(['Date','Ticker'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.set_index('Date')\n",
    "\n",
    "weekly_ff = (\n",
    "    df\n",
    "    .groupby('Ticker')\n",
    "    .resample('W-FRI')\n",
    "    .agg({\n",
    "        'Open':   'first',\n",
    "        'High':   'max',\n",
    "        'Low':    'min',\n",
    "        'Close':  'last',\n",
    "        'Volume': 'sum'\n",
    "    })\n",
    "    .dropna()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "weekly_ff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49afb2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2005-04-01</td>\n",
       "      <td>408.560736</td>\n",
       "      <td>429.405656</td>\n",
       "      <td>408.560736</td>\n",
       "      <td>421.067688</td>\n",
       "      <td>6336749</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2005-04-08</td>\n",
       "      <td>429.405713</td>\n",
       "      <td>579.489169</td>\n",
       "      <td>429.405713</td>\n",
       "      <td>529.461365</td>\n",
       "      <td>206700352</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2005-04-15</td>\n",
       "      <td>521.123391</td>\n",
       "      <td>550.306183</td>\n",
       "      <td>512.785332</td>\n",
       "      <td>521.123352</td>\n",
       "      <td>27473244</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2005-04-22</td>\n",
       "      <td>516.954428</td>\n",
       "      <td>516.954428</td>\n",
       "      <td>462.757603</td>\n",
       "      <td>475.264557</td>\n",
       "      <td>42606369</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2005-04-29</td>\n",
       "      <td>475.264542</td>\n",
       "      <td>475.264542</td>\n",
       "      <td>429.405670</td>\n",
       "      <td>429.405670</td>\n",
       "      <td>32741619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2025-02-28</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>157145100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2025-03-07</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>1035.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>155914900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2025-03-14</td>\n",
       "      <td>1010.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>985.000000</td>\n",
       "      <td>995.000000</td>\n",
       "      <td>148779500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2025-03-21</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>975.000000</td>\n",
       "      <td>175640800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2025-03-28</td>\n",
       "      <td>985.000000</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>945.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>99974600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1037 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price   Ticker       Date         Open         High          Low        Close  \\\n",
       "0      MEDC.JK 2005-04-01   408.560736   429.405656   408.560736   421.067688   \n",
       "1      MEDC.JK 2005-04-08   429.405713   579.489169   429.405713   529.461365   \n",
       "2      MEDC.JK 2005-04-15   521.123391   550.306183   512.785332   521.123352   \n",
       "3      MEDC.JK 2005-04-22   516.954428   516.954428   462.757603   475.264557   \n",
       "4      MEDC.JK 2005-04-29   475.264542   475.264542   429.405670   429.405670   \n",
       "...        ...        ...          ...          ...          ...          ...   \n",
       "1032   MEDC.JK 2025-02-28  1060.000000  1060.000000  1000.000000  1000.000000   \n",
       "1033   MEDC.JK 2025-03-07  1020.000000  1035.000000   990.000000  1005.000000   \n",
       "1034   MEDC.JK 2025-03-14  1010.000000  1025.000000   985.000000   995.000000   \n",
       "1035   MEDC.JK 2025-03-21  1000.000000  1025.000000   900.000000   975.000000   \n",
       "1036   MEDC.JK 2025-03-28   985.000000  1040.000000   945.000000  1025.000000   \n",
       "\n",
       "Price     Volume  Trend  \n",
       "0        6336749      0  \n",
       "1      206700352      1  \n",
       "2       27473244      0  \n",
       "3       42606369      0  \n",
       "4       32741619      0  \n",
       "...          ...    ...  \n",
       "1032   157145100      0  \n",
       "1033   155914900      1  \n",
       "1034   148779500      0  \n",
       "1035   175640800      0  \n",
       "1036    99974600      1  \n",
       "\n",
       "[1037 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) compute month‐over‐month % change on Close\n",
    "weekly_ff['Pct_Change'] = (\n",
    "    weekly_ff\n",
    "    .groupby('Ticker')['Close']\n",
    "    .pct_change()\n",
    ")\n",
    "\n",
    "weekly_ff['Trend'] = np.where(\n",
    "    weekly_ff['Pct_Change'] >=  0, 1,\n",
    "    np.where(weekly_ff['Pct_Change'] < 0, 0, 0)\n",
    ")\n",
    "\n",
    "# 3) (optional) drop the helper column\n",
    "weekly_ff.drop(columns='Pct_Change', inplace=True)\n",
    "\n",
    "# preview\n",
    "weekly_ff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6edb746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2005-04-01</td>\n",
       "      <td>0.203515</td>\n",
       "      <td>0.206522</td>\n",
       "      <td>0.224854</td>\n",
       "      <td>0.214193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2005-04-08</td>\n",
       "      <td>0.217807</td>\n",
       "      <td>0.305919</td>\n",
       "      <td>0.240644</td>\n",
       "      <td>0.289248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2005-04-15</td>\n",
       "      <td>0.280692</td>\n",
       "      <td>0.286592</td>\n",
       "      <td>0.303806</td>\n",
       "      <td>0.283475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2005-04-22</td>\n",
       "      <td>0.277834</td>\n",
       "      <td>0.264504</td>\n",
       "      <td>0.265909</td>\n",
       "      <td>0.251721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2005-04-29</td>\n",
       "      <td>0.249250</td>\n",
       "      <td>0.236893</td>\n",
       "      <td>0.240644</td>\n",
       "      <td>0.219967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2025-02-28</td>\n",
       "      <td>0.650163</td>\n",
       "      <td>0.624149</td>\n",
       "      <td>0.672880</td>\n",
       "      <td>0.615063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2025-03-07</td>\n",
       "      <td>0.622737</td>\n",
       "      <td>0.607592</td>\n",
       "      <td>0.665305</td>\n",
       "      <td>0.618525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2025-03-14</td>\n",
       "      <td>0.615881</td>\n",
       "      <td>0.600970</td>\n",
       "      <td>0.661517</td>\n",
       "      <td>0.611601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2025-03-21</td>\n",
       "      <td>0.609025</td>\n",
       "      <td>0.600970</td>\n",
       "      <td>0.597128</td>\n",
       "      <td>0.597752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2025-03-28</td>\n",
       "      <td>0.598740</td>\n",
       "      <td>0.610904</td>\n",
       "      <td>0.631217</td>\n",
       "      <td>0.632374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1037 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price   Ticker       Date      Open      High       Low     Close\n",
       "0      MEDC.JK 2005-04-01  0.203515  0.206522  0.224854  0.214193\n",
       "1      MEDC.JK 2005-04-08  0.217807  0.305919  0.240644  0.289248\n",
       "2      MEDC.JK 2005-04-15  0.280692  0.286592  0.303806  0.283475\n",
       "3      MEDC.JK 2005-04-22  0.277834  0.264504  0.265909  0.251721\n",
       "4      MEDC.JK 2005-04-29  0.249250  0.236893  0.240644  0.219967\n",
       "...        ...        ...       ...       ...       ...       ...\n",
       "1032   MEDC.JK 2025-02-28  0.650163  0.624149  0.672880  0.615063\n",
       "1033   MEDC.JK 2025-03-07  0.622737  0.607592  0.665305  0.618525\n",
       "1034   MEDC.JK 2025-03-14  0.615881  0.600970  0.661517  0.611601\n",
       "1035   MEDC.JK 2025-03-21  0.609025  0.600970  0.597128  0.597752\n",
       "1036   MEDC.JK 2025-03-28  0.598740  0.610904  0.631217  0.632374\n",
       "\n",
       "[1037 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assume weekly_ff is your DataFrame\n",
    "weekly_ff['Date'] = pd.to_datetime(weekly_ff['Date'])\n",
    "train_start = '2005-04-01'\n",
    "train_end   = '2024-03-31'\n",
    "\n",
    "# store scalers if you need to inverse_transform later\n",
    "scalers = {}\n",
    "\n",
    "for ticker, grp in weekly_ff.groupby('Ticker'):\n",
    "    # boolean masks for this ticker\n",
    "    mask_all   = weekly_ff['Ticker'] == ticker\n",
    "    mask_train = mask_all & weekly_ff['Date'].between(train_start, train_end)\n",
    "    mask_test  = mask_all & (weekly_ff['Date'] > train_end)\n",
    "    \n",
    "    # fit scaler on TRAIN close prices\n",
    "    for feature in ['Open', 'High', 'Low', 'Close']:\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        scaler.fit(weekly_ff.loc[mask_train, [feature]])\n",
    "        scalers[ticker] = scaler\n",
    "        \n",
    "        # transform both train and test\n",
    "        weekly_ff.loc[mask_train, feature] = scaler.transform(weekly_ff.loc[mask_train, [feature]])\n",
    "        weekly_ff.loc[mask_test,  feature] = scaler.transform(weekly_ff.loc[mask_test,  [feature]])\n",
    "\n",
    "weekly_ff[['Ticker', 'Date', 'Open', 'High', 'Low', 'Close']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed2d8a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_ff[['Ticker', 'Date', 'Open', 'High', 'Low', 'Close', 'Trend']].to_csv('Weekly_Stock_Price.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2df77d",
   "metadata": {},
   "source": [
    "# Preprocess Disclosure Tone Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "288b3cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.read_csv('Result/zs_multilabel_qwen.csv')\n",
    "grouped_df = result_df.groupby(['Ticker', 'Year']).sum()\n",
    "drop_cols = [\n",
    "    'Positive', 'Negative', 'Uncertainty',\n",
    "    'Litigious', 'Strong_Modal', 'Weak_Modal', 'Constraining', 'Sentence'\n",
    "]\n",
    "cols_pred = [\n",
    "    'Positive_Pred', 'Negative_Pred', 'Uncertainty_Pred',\n",
    "    'Litigious_Pred', 'Strong_Modal_Pred', 'Weak_Modal_Pred', 'Constraining_Pred'\n",
    "]\n",
    "\n",
    "# compute row-sums over those columns\n",
    "row_sums = grouped_df[cols_pred].sum(axis=1)\n",
    "\n",
    "# replace each value with its percentage of the row total\n",
    "grouped_df[cols_pred] = grouped_df[cols_pred].div(row_sums, axis=0)\n",
    "grouped_df = grouped_df.drop(columns=drop_cols).reset_index()\n",
    "grouped_df.to_csv('DisclosureTone/tone_zs_multilabel_qwen.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "474c72be",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.read_csv('Result/zs_multiclass_fin-r1.csv')\n",
    "drop_cols = [\n",
    "    'Positive', 'Negative', 'Uncertainty',\n",
    "    'Litigious', 'Strong_Modal', 'Weak_Modal', 'Constraining', 'Sentence'\n",
    "]\n",
    "cols_pred = [\n",
    "    'Positive_Pred', 'Negative_Pred', 'Uncertainty_Pred',\n",
    "    'Litigious_Pred', 'Strong_Modal_Pred', 'Weak_Modal_Pred', 'Constraining_Pred'\n",
    "]\n",
    "# replace(2,1) for 2 class classification and replace(2,0) for 1 class classification\n",
    "result_df[cols_pred] = result_df[cols_pred].replace(2, 1)\n",
    "grouped_df = result_df.groupby(['Ticker', 'Year']).sum()\n",
    "\n",
    "# compute row-sums over those columns\n",
    "row_sums = grouped_df[cols_pred].sum(axis=1)\n",
    "\n",
    "# replace each value with its percentage of the row total\n",
    "grouped_df[cols_pred] = grouped_df[cols_pred].div(row_sums, axis=0)\n",
    "grouped_df = grouped_df.drop(columns=drop_cols).reset_index()\n",
    "grouped_df.to_csv('DisclosureTone/tone_zs_multiclass-2_fin-r1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0c9de5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Year</th>\n",
       "      <th>Positive_Pred</th>\n",
       "      <th>Negative_Pred</th>\n",
       "      <th>Uncertainty_Pred</th>\n",
       "      <th>Litigious_Pred</th>\n",
       "      <th>Strong_Modal_Pred</th>\n",
       "      <th>Weak_Modal_Pred</th>\n",
       "      <th>Constraining_Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.127451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.142132</td>\n",
       "      <td>0.121827</td>\n",
       "      <td>0.299492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055838</td>\n",
       "      <td>0.177665</td>\n",
       "      <td>0.203046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.147727</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.244318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.244565</td>\n",
       "      <td>0.293478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>0.146739</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.257511</td>\n",
       "      <td>0.154506</td>\n",
       "      <td>0.240343</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>0.064378</td>\n",
       "      <td>0.094421</td>\n",
       "      <td>0.180258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>0.161538</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.073077</td>\n",
       "      <td>0.169231</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.458015</td>\n",
       "      <td>0.160305</td>\n",
       "      <td>0.152672</td>\n",
       "      <td>0.019084</td>\n",
       "      <td>0.034351</td>\n",
       "      <td>0.076336</td>\n",
       "      <td>0.099237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076389</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.173611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.447619</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.123810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.446281</td>\n",
       "      <td>0.256198</td>\n",
       "      <td>0.082645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074380</td>\n",
       "      <td>0.074380</td>\n",
       "      <td>0.066116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.347458</td>\n",
       "      <td>0.245763</td>\n",
       "      <td>0.135593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.059322</td>\n",
       "      <td>0.127119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.271605</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.074074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.102041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.175439</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.017544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.183673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>MEDC.JK</td>\n",
       "      <td>2023</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.021739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0   Ticker  Year  Positive_Pred  Negative_Pred  Uncertainty_Pred  \\\n",
       "0            0  MEDC.JK  2004       0.235294       0.147059          0.254902   \n",
       "1            1  MEDC.JK  2005       0.142132       0.121827          0.299492   \n",
       "2            2  MEDC.JK  2006       0.062500       0.147727          0.312500   \n",
       "3            3  MEDC.JK  2007       0.125000       0.244565          0.293478   \n",
       "4            4  MEDC.JK  2008       0.257511       0.154506          0.240343   \n",
       "5            5  MEDC.JK  2009       0.134615       0.161538          0.288462   \n",
       "6            6  MEDC.JK  2010       0.458015       0.160305          0.152672   \n",
       "7            7  MEDC.JK  2011       0.361111       0.069444          0.208333   \n",
       "8            8  MEDC.JK  2012       0.447619       0.171429          0.123810   \n",
       "9            9  MEDC.JK  2013       0.446281       0.256198          0.082645   \n",
       "10          10  MEDC.JK  2014       0.347458       0.245763          0.135593   \n",
       "11          11  MEDC.JK  2015       0.271605       0.407407          0.148148   \n",
       "12          12  MEDC.JK  2016       0.408163       0.224490          0.142857   \n",
       "13          13  MEDC.JK  2017       0.526316       0.175439          0.210526   \n",
       "14          14  MEDC.JK  2018       0.523810       0.238095          0.142857   \n",
       "15          15  MEDC.JK  2019       0.533333       0.233333          0.166667   \n",
       "16          16  MEDC.JK  2020       0.340000       0.260000          0.220000   \n",
       "17          17  MEDC.JK  2021       0.367347       0.040816          0.244898   \n",
       "18          18  MEDC.JK  2022       0.521739       0.065217          0.108696   \n",
       "19          19  MEDC.JK  2023       0.543478       0.152174          0.130435   \n",
       "\n",
       "    Litigious_Pred  Strong_Modal_Pred  Weak_Modal_Pred  Constraining_Pred  \n",
       "0         0.000000           0.058824         0.176471           0.127451  \n",
       "1         0.000000           0.055838         0.177665           0.203046  \n",
       "2         0.000000           0.045455         0.187500           0.244318  \n",
       "3         0.000000           0.016304         0.146739           0.173913  \n",
       "4         0.008584           0.064378         0.094421           0.180258  \n",
       "5         0.019231           0.073077         0.169231           0.153846  \n",
       "6         0.019084           0.034351         0.076336           0.099237  \n",
       "7         0.000000           0.076389         0.111111           0.173611  \n",
       "8         0.000000           0.076190         0.085714           0.095238  \n",
       "9         0.000000           0.074380         0.074380           0.066116  \n",
       "10        0.000000           0.084746         0.059322           0.127119  \n",
       "11        0.000000           0.037037         0.061728           0.074074  \n",
       "12        0.000000           0.040816         0.081633           0.102041  \n",
       "13        0.000000           0.017544         0.052632           0.017544  \n",
       "14        0.000000           0.023810         0.023810           0.047619  \n",
       "15        0.000000           0.033333         0.000000           0.033333  \n",
       "16        0.000000           0.020000         0.080000           0.080000  \n",
       "17        0.000000           0.081633         0.081633           0.183673  \n",
       "18        0.000000           0.152174         0.065217           0.086957  \n",
       "19        0.000000           0.043478         0.108696           0.021739  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tone_df = pd.read_csv('DisclosureTone/tone_icl_multilabel_qwen.csv')\n",
    "tone_df['Ticker'] = tone_df['Ticker'] + '.JK'\n",
    "tone_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669cfb4e",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b643dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(price_filename, tone_filename):\n",
    "   weekly_ff = pd.read_csv(price_filename)\n",
    "   weekly_ff['Date'] = pd.to_datetime(weekly_ff['Date'])\n",
    "   tone_df = pd.read_csv(tone_filename)\n",
    "   tone_df['Ticker'] = tone_df['Ticker'] + '.JK'\n",
    "\n",
    "   d = weekly_ff['Date']\n",
    "   weekly_ff['tone_year'] = d.dt.year - 1 - (d.dt.month < 4).astype(int)\n",
    "   tone_df = tone_df.rename(columns={'Year':'tone_year'})\n",
    "\n",
    "   merged = (\n",
    "      weekly_ff\n",
    "         .merge(\n",
    "            tone_df,\n",
    "            on=['Ticker','tone_year'],\n",
    "            how='left'\n",
    "         )\n",
    "         .drop(columns=['tone_year'])\n",
    "   )\n",
    "   merged = merged.fillna(0)\n",
    "   return merged\n",
    "\n",
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_icl_multilabel_fin-r1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaa821d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(df, n_lags=12, tone=False, batch_size=64):\n",
    "    train_start = pd.to_datetime('2005-04-01')\n",
    "    train_end   = pd.to_datetime('2024-03-31')\n",
    "\n",
    "    if tone:\n",
    "        feature_cols = [\n",
    "            'Open', 'High', 'Low', 'Close', \n",
    "            'Positive_Pred', 'Negative_Pred', 'Uncertainty_Pred', 'Litigious_Pred', \n",
    "            'Strong_Modal_Pred', 'Weak_Modal_Pred', 'Constraining_Pred'\n",
    "        ]\n",
    "    else:\n",
    "        feature_cols = [\n",
    "            'Open', 'High', 'Low', 'Close'\n",
    "        ]\n",
    "    X_train, X_test = [], []\n",
    "    y_train, y_test = [], []\n",
    "    for ticker, group in df.groupby('Ticker'):\n",
    "        group = group.sort_values('Date')\n",
    "        feats  = group[feature_cols].values\n",
    "        dates = group['Date'].values\n",
    "\n",
    "        # slide over windows\n",
    "        for i in range(n_lags, len(group)):\n",
    "            Xw = feats[i-n_lags : i]\n",
    "            yw = feats[i][3]\n",
    "            label_date = dates[i]\n",
    "\n",
    "            if train_start <= label_date <= train_end:\n",
    "                X_train.append(Xw)\n",
    "                y_train.append(yw)\n",
    "            elif label_date > train_end:\n",
    "                X_test.append(Xw)\n",
    "                y_test.append(yw)\n",
    "    \n",
    "    X_train = np.stack(X_train, axis=0)\n",
    "    X_test  = np.stack(X_test,  axis=0)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test  = np.array(y_test) \n",
    "\n",
    "    train_ds = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).float())\n",
    "    test_ds  = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).float())\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=batch_size)\n",
    "\n",
    "    return X_train.shape[2], train_loader, test_loader\n",
    "\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e47da98",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d56d5e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_rate):\n",
    "        super(BiLSTMModel, self).__init__()\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.lstm2 = nn.LSTM(hidden_size * 2, hidden_size, num_layers, batch_first=True, bidirectional=True)  # Input size doubles because it's bidirectional\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.fc1 = nn.Linear(hidden_size * 2, 16)  # First dense layer after second LSTM\n",
    "        self.fc2 = nn.Linear(16, 1)  # Second dense layer outputs the final prediction\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(x)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu2(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc1(x[:, -1, :])  # Apply first dense layer to the last time step output\n",
    "        x = self.fc2(x)  # Apply second dense layer\n",
    "        return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c717f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss, self).__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, predicted, actual):\n",
    "        return torch.sqrt(self.mse(predicted, actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed964dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "input_dim = input_dim\n",
    "hidden_dim = 64\n",
    "layer_dim  = 2\n",
    "dropout    = 0.2\n",
    "lr         = 1e-3\n",
    "epochs     = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82fccf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, test_loader):\n",
    "    set_seed()\n",
    "    model = BiLSTMModel(input_dim, hidden_dim, layer_dim, dropout)\n",
    "    model.to(device)\n",
    "\n",
    "    # Regression setup with RMSE loss\n",
    "    criterion = RMSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "    pbar = tqdm(range(1, epochs + 1), desc='Epoch', unit='epoch')\n",
    "    for epoch in pbar:\n",
    "        # --- Training ---\n",
    "        model.train()\n",
    "        train_loss_accum = 0.0\n",
    "        train_count = 0\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_accum += loss.item() * xb.size(0)\n",
    "            train_count += xb.size(0)\n",
    "\n",
    "        train_loss = train_loss_accum / train_count\n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "        # --- Evaluation ---\n",
    "        model.eval()\n",
    "        all_test_preds = []\n",
    "        all_test_labels = []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in test_loader:\n",
    "                xb = xb.to(device)\n",
    "                preds = model(xb).cpu().numpy()\n",
    "                all_test_preds.extend(preds)\n",
    "                all_test_labels.extend(yb.numpy())\n",
    "        test_rmse = np.sqrt(mean_squared_error(all_test_labels, all_test_preds))\n",
    "\n",
    "        pbar.set_postfix({'Train RMSE': f'{train_loss:.4f}', 'Test RMSE': f'{test_rmse:.4f}'})\n",
    "\n",
    "        if optimizer.param_groups[0]['lr'] < 1e-07:\n",
    "            break\n",
    "\n",
    "    # --- Final detailed report on test set ---\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb = xb.to(device)\n",
    "            preds = model(xb).cpu().numpy()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(yb.numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    mse = mean_squared_error(all_labels, all_preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(all_labels, all_preds)\n",
    "\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE:  {mae:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9d2c9bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   0%|          | 0/100 [00:00<?, ?epoch/s, Train RMSE=0.1835, Test RMSE=0.5011]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  45%|████▌     | 45/100 [00:03<00:04, 12.45epoch/s, Train RMSE=0.0377, Test RMSE=0.0423]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0423\n",
      "MAE:  0.0340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_icl_multilabel_fin-r1.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=12, tone=False)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/ohlc_12.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6888c845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   4%|▍         | 4/100 [00:00<00:07, 12.59epoch/s, Train RMSE=0.0671, Test RMSE=0.0704]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  39%|███▉      | 39/100 [00:03<00:04, 12.32epoch/s, Train RMSE=0.0392, Test RMSE=0.0426]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0426\n",
      "MAE:  0.0337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_icl_multilabel_fin-r1.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=24, tone=False)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/ohlc_24.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9557ea7b",
   "metadata": {},
   "source": [
    "# ICL Weekly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46420ddf",
   "metadata": {},
   "source": [
    "## ICL Multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1a8a00e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   2%|▏         | 2/100 [00:00<00:07, 12.56epoch/s, Train RMSE=0.1621, Test RMSE=0.3847]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  55%|█████▌    | 55/100 [00:04<00:03, 12.48epoch/s, Train RMSE=0.0382, Test RMSE=0.0460]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0460\n",
      "MAE:  0.0345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_icl_multilabel_fin-r1.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=12, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/icl_multilabel_fin-r1_12.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9f9320d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   2%|▏         | 2/100 [00:00<00:07, 12.46epoch/s, Train RMSE=0.1090, Test RMSE=0.1357]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  57%|█████▋    | 57/100 [00:04<00:03, 12.35epoch/s, Train RMSE=0.0404, Test RMSE=0.0472]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0472\n",
      "MAE:  0.0354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_icl_multilabel_fin-r1.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=24, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/icl_multilabel_fin-r1_24.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e21854ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   4%|▍         | 4/100 [00:00<00:07, 12.64epoch/s, Train RMSE=0.0679, Test RMSE=0.0690]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  61%|██████    | 61/100 [00:04<00:03, 12.60epoch/s, Train RMSE=0.0383, Test RMSE=0.0458]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0458\n",
      "MAE:  0.0345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_icl_multilabel_qwen.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=12, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/icl_multilabel_qwen_12.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7207e8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   8%|▊         | 8/100 [00:00<00:07, 12.85epoch/s, Train RMSE=0.0585, Test RMSE=0.1142]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  57%|█████▋    | 57/100 [00:04<00:03, 12.62epoch/s, Train RMSE=0.0414, Test RMSE=0.0477]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0477\n",
      "MAE:  0.0363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_icl_multilabel_qwen.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=24, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/icl_multilabel_qwen_24.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1e677e",
   "metadata": {},
   "source": [
    "## ICL Multiclass-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d1177c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   2%|▏         | 2/100 [00:00<00:07, 12.85epoch/s, Train RMSE=0.1617, Test RMSE=0.3818]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  54%|█████▍    | 54/100 [00:04<00:03, 12.71epoch/s, Train RMSE=0.0375, Test RMSE=0.0443]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0443\n",
      "MAE:  0.0330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_icl_multiclass-2_fin-r1.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=12, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/icl_multiclass-2_fin-r1_12.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2316b0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   6%|▌         | 6/100 [00:00<00:07, 12.81epoch/s, Train RMSE=0.0675, Test RMSE=0.0894]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  39%|███▉      | 39/100 [00:03<00:04, 12.51epoch/s, Train RMSE=0.0450, Test RMSE=0.0456]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0456\n",
      "MAE:  0.0348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_icl_multiclass-2_fin-r1.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=24, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/icl_multiclass-2_fin-r1_24.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7d69ab04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   0%|          | 0/100 [00:00<?, ?epoch/s, Train RMSE=0.2838, Test RMSE=0.5069]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  57%|█████▋    | 57/100 [00:04<00:03, 12.81epoch/s, Train RMSE=0.0377, Test RMSE=0.0417]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0417\n",
      "MAE:  0.0317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_icl_multiclass-2_qwen.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=12, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/icl_multiclass-2_qwen_12.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "57813ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   8%|▊         | 8/100 [00:00<00:07, 12.91epoch/s, Train RMSE=0.0611, Test RMSE=0.0721]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  39%|███▉      | 39/100 [00:03<00:04, 12.60epoch/s, Train RMSE=0.0452, Test RMSE=0.0441]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0441\n",
      "MAE:  0.0339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_icl_multiclass-2_qwen.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=24, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/icl_multiclass-2_qwen_24.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073ada75",
   "metadata": {},
   "source": [
    "## ICL Multiclass-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5897c385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   6%|▌         | 6/100 [00:00<00:07, 12.92epoch/s, Train RMSE=0.0601, Test RMSE=0.0557]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  57%|█████▋    | 57/100 [00:04<00:03, 12.78epoch/s, Train RMSE=0.0378, Test RMSE=0.0448]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0448\n",
      "MAE:  0.0335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_icl_multiclass-1_fin-r1.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=12, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/icl_multiclass-1_fin-r1_12.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "708ee263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   4%|▍         | 4/100 [00:00<00:07, 12.92epoch/s, Train RMSE=0.0836, Test RMSE=0.1230]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  54%|█████▍    | 54/100 [00:04<00:03, 12.73epoch/s, Train RMSE=0.0397, Test RMSE=0.0459]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0459\n",
      "MAE:  0.0345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_icl_multiclass-1_fin-r1.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=24, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/icl_multiclass-1_fin-r1_24.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "65ea465c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   8%|▊         | 8/100 [00:00<00:07, 13.02epoch/s, Train RMSE=0.0549, Test RMSE=0.0628]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  57%|█████▋    | 57/100 [00:04<00:03, 12.77epoch/s, Train RMSE=0.0378, Test RMSE=0.0424]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0424\n",
      "MAE:  0.0321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_icl_multiclass-1_qwen.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=12, tone=True)\n",
    "mdoel = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/icl_multiclass-1_qwen_12.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b4e7aa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   2%|▏         | 2/100 [00:00<00:07, 12.81epoch/s, Train RMSE=0.1076, Test RMSE=0.1341]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  53%|█████▎    | 53/100 [00:04<00:03, 12.62epoch/s, Train RMSE=0.0415, Test RMSE=0.0422]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0422\n",
      "MAE:  0.0330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_icl_multiclass-1_qwen.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=24, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/icl_multiclass-1_qwen_24.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88b1bb9",
   "metadata": {},
   "source": [
    "# Zero-Shot Weekly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d04cc25",
   "metadata": {},
   "source": [
    "## ZS Multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4acf5d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   4%|▍         | 4/100 [00:00<00:07, 12.99epoch/s, Train RMSE=0.0767, Test RMSE=0.1498]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  61%|██████    | 61/100 [00:04<00:03, 12.80epoch/s, Train RMSE=0.0381, Test RMSE=0.0498]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0498\n",
      "MAE:  0.0388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_zs_multilabel_fin-r1.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=12, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/zs_multilabel_fin-r1_12.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1cbaca55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   2%|▏         | 2/100 [00:00<00:07, 12.73epoch/s, Train RMSE=0.1554, Test RMSE=0.3465]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 70/100 [00:05<00:02, 12.62epoch/s, Train RMSE=0.0404, Test RMSE=0.0536]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0536\n",
      "MAE:  0.0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_zs_multilabel_fin-r1.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=24, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/zs_multilabel_fin-r1_24.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "35bdb9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   4%|▍         | 4/100 [00:00<00:07, 12.81epoch/s, Train RMSE=0.0766, Test RMSE=0.1517]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  54%|█████▍    | 54/100 [00:04<00:03, 12.69epoch/s, Train RMSE=0.0376, Test RMSE=0.0493]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0493\n",
      "MAE:  0.0378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_zs_multilabel_qwen.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=12, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/zs_multilabel_qwen_12.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "311af96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   6%|▌         | 6/100 [00:00<00:07, 12.84epoch/s, Train RMSE=0.0573, Test RMSE=0.0972]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 70/100 [00:05<00:02, 12.64epoch/s, Train RMSE=0.0403, Test RMSE=0.0499]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0499\n",
      "MAE:  0.0382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_zs_multilabel_qwen.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=24, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/zs_multilabel_qwen_24.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee93eedb",
   "metadata": {},
   "source": [
    "## ZS Multiclass-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e4e6b29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   4%|▍         | 4/100 [00:00<00:07, 12.81epoch/s, Train RMSE=0.0680, Test RMSE=0.0684]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  57%|█████▋    | 57/100 [00:04<00:03, 12.68epoch/s, Train RMSE=0.0379, Test RMSE=0.0433]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0433\n",
      "MAE:  0.0326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_zs_multiclass-2_fin-r1.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=12, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/zs_multiclass-2_fin-r1_12.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e25b4ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   4%|▍         | 4/100 [00:00<00:07, 12.80epoch/s, Train RMSE=0.0836, Test RMSE=0.1248]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  57%|█████▋    | 57/100 [00:04<00:03, 12.68epoch/s, Train RMSE=0.0416, Test RMSE=0.0452]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0452\n",
      "MAE:  0.0344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_zs_multiclass-2_fin-r1.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=24, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/zs_multiclass-2_fin-r1_24.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "10e5fe5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   4%|▍         | 4/100 [00:00<00:07, 12.96epoch/s, Train RMSE=0.0766, Test RMSE=0.1475]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  55%|█████▌    | 55/100 [00:04<00:03, 12.76epoch/s, Train RMSE=0.0383, Test RMSE=0.0433]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0433\n",
      "MAE:  0.0326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_zs_multiclass-2_qwen.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=12, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/zs_multiclass-2_qwen_12.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "10b1d139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   6%|▌         | 6/100 [00:00<00:07, 12.83epoch/s, Train RMSE=0.0667, Test RMSE=0.0845]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  39%|███▉      | 39/100 [00:03<00:04, 12.58epoch/s, Train RMSE=0.0452, Test RMSE=0.0448]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0448\n",
      "MAE:  0.0345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_zs_multiclass-2_qwen.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=24, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/zs_multiclass-2_qwen_24.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a2581e",
   "metadata": {},
   "source": [
    "## ZS Multiclass-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7f313af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   2%|▏         | 2/100 [00:00<00:07, 12.92epoch/s, Train RMSE=0.1618, Test RMSE=0.3859]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  57%|█████▋    | 57/100 [00:04<00:03, 12.70epoch/s, Train RMSE=0.0378, Test RMSE=0.0440]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0440\n",
      "MAE:  0.0331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_zs_multiclass-1_fin-r1.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=12, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/zs_multiclass-1_fin-r1_12.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "096e4f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:  10%|█         | 10/100 [00:00<00:06, 12.90epoch/s, Train RMSE=0.0528, Test RMSE=0.0755]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  49%|████▉     | 49/100 [00:03<00:04, 12.61epoch/s, Train RMSE=0.0420, Test RMSE=0.0460]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0460\n",
      "MAE:  0.0351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_zs_multiclass-1_fin-r1.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=24, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/zs_multiclass-1_fin-r1_24.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "01b1cf1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   2%|▏         | 2/100 [00:00<00:07, 12.86epoch/s, Train RMSE=0.1613, Test RMSE=0.3833]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  57%|█████▋    | 57/100 [00:04<00:03, 12.81epoch/s, Train RMSE=0.0378, Test RMSE=0.0442]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0442\n",
      "MAE:  0.0331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_zs_multiclass-1_qwen.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=12, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/zs_multiclass-1_qwen_12.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "52411f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/data/fraud2024_1/env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Epoch:   2%|▏         | 2/100 [00:00<00:07, 12.84epoch/s, Train RMSE=0.1074, Test RMSE=0.1363]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  53%|█████▎    | 53/100 [00:04<00:03, 12.71epoch/s, Train RMSE=0.0409, Test RMSE=0.0436]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0436\n",
      "MAE:  0.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timeseries_df = create_dataset('Weekly_Stock_Price.csv', 'DisclosureTone/tone_zs_multiclass-1_qwen.csv')\n",
    "input_dim, train_loader, test_loader = create_dataloader(timeseries_df, n_lags=24, tone=True)\n",
    "model = train_model(train_loader, test_loader)\n",
    "# torch.save(model.state_dict(), \"Model/zs_multiclass-1_qwen_24.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
